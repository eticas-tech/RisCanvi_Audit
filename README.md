# Automating (In) Justice? An Adversarial Audit of RisCanvi – GitHub Repository 

The present repository is the quantitative analysis done for the Adversarial Audit of RisCanvi. At Eticas we wanted to contribute to the debate by conducting the first ever adversarial audit of an AI criminal justice system in Europe: the RisCanvi tool. In use since 2009 in Catalonia, Spain, and specifically designed for assessing recidivism and violence risk among inmates. RisCanvi wields influence over parole and sentencing decisions, and while some authors have raised concerns about its fairness, accuracy and transparency, most people, inmates, lawyers and court actors are unaware of its existence or inner workings. 

In our quest to understand RisCanvi, the Eticas team conducted an Adversarial Audit using a dual-method approach. This involved an Ethnographic Audit, which included interviews with inmates and staff both in and outside the criminal justice system, and a Comparative Output Audit, based on public data on the inmate population and recidivism, and comparing it with RisCanvi’s risk factors and risk behaviors. 

What we have found with RisCanvi is a system that is not known by those whom it impacts the most, inmates; that is not trusted by many of those who work with it, who are also not trained on its functioning and weights; that is opaque and has failed to adhere to current regulation on the use of automated decision-making systems in Spain, where AI audits are required since 2016. Above all, however, our data shows that RisCanvi may not be fair nor reliable, and that it has failed to do what AI should do best: standardize outcomes and limit discretion. Consistent with earlier studies, we do not find RisCanvi to be reliable, as this would require a clear relationship between risk factors, risk behaviors and risk scores.  

Based on the available data, we conclude that RisCanvi does not work, and is not currently able to provide the necessary guarantees to inmates, lawyers, judges and criminal justice authorities. The present repository includes the efforts developed by Eticas during the Comparative Output Audit. The process described by the repository includes four main analyses: logistic regression, intersection analysis, factor prevalence and spectral clustering.  

The repository is organized in a simple structure. All the analysis and code are concentrated in the Jupyter Notebook “RisCanvi Audit (Python Code)”. Additionally, the user can find the complete and executive summary of the audit report by the names “Automating InJustice – An Adversarial Audit of RisCanvi” and “RisCanvi-Audit_Resumen”. The repository also is composed of four folders with different information. First, the folder codebooks contain the original codebooks of each dataset used by the audit. Second, the folder named “datasets” contains the data used in the research. Third, the folder named “img” contains all the figures and visualizations made by the code. Lastly, the folder named “reports” includes the original reports for each dataset with their analysis realized by the Center of Legal Studies and Specialized Training (CEJFE).  
